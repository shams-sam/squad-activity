{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import cv2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image, text\n",
    "from keras.utils import np_utils as u\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "K_FOLDS=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pkl.load(open('./data/df_train.dump.pkl', 'rb'))\n",
    "df_valid = pkl.load(open('./data/df_valid.dump.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "labels_train = []\n",
    "objects_train = []\n",
    "attributes_train = []\n",
    "missed = []\n",
    "for idx, rows in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    img = cv2.imread(utility.image_location(rows['imageId'], config.RESIZED_TRAIN_DIR))\n",
    "    if type(img) != np.ndarray:\n",
    "        missed.append(rows['imageId'])\n",
    "        continue\n",
    "    h, w, c = img.shape\n",
    "    app_img = np.empty(shape=(config.MAX_PIXEL, config.MAX_PIXEL, 3), dtype=np.uint8)\n",
    "    app_img[:h, :w] = img\n",
    "    X_train.append(app_img)\n",
    "    labels_train.append(rows['label'])\n",
    "    objects_train.append(rows['object'])\n",
    "    attributes_train.append(rows['attribute'])\n",
    "print(\"%d missed.\" % len(missed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = []\n",
    "labels_valid = []\n",
    "objects_valid = []\n",
    "attributes_valid = []\n",
    "missed = []\n",
    "for idx, rows in tqdm(df_valid.iterrows(), total=len(df_valid)):\n",
    "    img = cv2.imread(utility.image_location(rows['imageId'], config.RESIZED_VALID_DIR))\n",
    "    if type(img) != np.ndarray:\n",
    "        missed.append(rows['imageId'])\n",
    "        continue\n",
    "    h, w, c = img.shape\n",
    "    app_img = np.empty(shape=(config.MAX_PIXEL, config.MAX_PIXEL, 3), dtype=np.uint8)\n",
    "    app_img[:h, :w] = img\n",
    "    X_valid.append(app_img)\n",
    "    labels_valid.append(rows['object'])\n",
    "    objects_valid.append(rows['object'])\n",
    "    attributes_valid.append(rows['attribute'])\n",
    "print(\"%d missed.\" % len(missed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = text.Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels_train)\n",
    "y_train = label_tokenizer.texts_to_sequences(labels_train)\n",
    "y_valid = label_tokenizer.texts_to_sequences(labels_valid)\n",
    "y_train = np.array([_[0] for _ in y_train])\n",
    "y_valid = np.array([_[0] for _ in y_valid])\n",
    "cls_wgt = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "cls_wgt = np.array([0] + cls_wgt.tolist())\n",
    "cls_wgt = {idx: value for idx, value in enumerate(cls_wgt)}\n",
    "cls_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train.astype('float32')/255.0, X_valid.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_valid:\", X_valid.shape)\n",
    "print(\"y_valid:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((X_train, X_valid))\n",
    "y = np.hstack((y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same',\n",
    "             activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer=SGD(momentum=0.5, decay=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "bst_model_path = './models/object_model.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, (train_indices, valid_indices) in enumerate(skf.split(X, y)):\n",
    "    print(\"Training on fold \" + str(idx+1) + \"/\" + str(K_FOLDS) + \"...\")\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_valid, y_valid = X[valid_indices], y[valid_indices]\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_valid = to_categorical(y_valid)\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=50, \n",
    "        validation_data=(X_valid, y_valid), \n",
    "        shuffle=True, \n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        batch_size=16\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.2f\" % (model.evaluate(X_valid, y_valid)[-1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(label_tokenizer, open('./models/object_model_label_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, c = img.shape\n",
    "    ip = np.empty(shape=(1, config.MAX_PIXEL, config.MAX_PIXEL, 3))\n",
    "    ip[0, :h, :w] = img\n",
    "    prediction = model.predict(ip)\n",
    "    return prediction[:, 1:][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class('./resized_test/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "resized_test = os.listdir(config.RESIZED_TEST_DIR)\n",
    "for _ in tqdm(resized_test, total=len(resized_test)):\n",
    "    img_path = config.RESIZED_TEST_DIR + \"/\" + _\n",
    "    all_rows.append([img_path] + predict_class(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.DataFrame(all_rows, columns = ['img_path', 'dress', 'outerwear', 'pants', 'shoe'])\n",
    "pkl.dump(df_test, open('df_test.pkl', 'wb'))\n",
    "df_test = pkl.load(open('df_test.pkl', 'rb'))\n",
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import cv2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image, text\n",
    "from keras.utils import np_utils as u\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "K_FOLDS=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pkl.load(open('./data/df_train.dump.pkl', 'rb'))\n",
    "df_valid = pkl.load(open('./data/df_valid.dump.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageId</th>\n",
       "      <th>labelId</th>\n",
       "      <th>taskId</th>\n",
       "      <th>object</th>\n",
       "      <th>attribute</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>dress</td>\n",
       "      <td>decoration</td>\n",
       "      <td>printed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>dress</td>\n",
       "      <td>color</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imageId labelId taskId object   attribute    label\n",
       "0       1       6      5  dress  decoration  printed\n",
       "1       2       7      6  dress       color   purple"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageId</th>\n",
       "      <th>labelId</th>\n",
       "      <th>taskId</th>\n",
       "      <th>object</th>\n",
       "      <th>attribute</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shoe</td>\n",
       "      <td>gender</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>shoe</td>\n",
       "      <td>age</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imageId labelId taskId object attribute  label\n",
       "0       1       1      1   shoe    gender    men\n",
       "1       1       2      2   shoe       age  adult"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2958 missed.\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "labels_train = []\n",
    "missed = []\n",
    "for idx, rows in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    img = cv2.imread(utility.image_location(rows['imageId'], config.RESIZED_TRAIN_DIR))\n",
    "    if type(img) != np.ndarray:\n",
    "        missed.append(rows['imageId'])\n",
    "        continue\n",
    "    h, w, c = img.shape\n",
    "    app_img = np.empty(shape=(config.MAX_PIXEL, config.MAX_PIXEL, 3), dtype=np.uint8)\n",
    "    app_img[:h, :w] = img\n",
    "    X_train.append(app_img)\n",
    "    labels_train.append(rows['object'])\n",
    "print(\"%d missed.\" % len(missed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "532 missed.\n"
     ]
    }
   ],
   "source": [
    "X_valid = []\n",
    "labels_valid = []\n",
    "missed = []\n",
    "for idx, rows in tqdm(df_valid.iterrows(), total=len(df_valid)):\n",
    "    img = cv2.imread(utility.image_location(rows['imageId'], config.RESIZED_VALID_DIR))\n",
    "    if type(img) != np.ndarray:\n",
    "        missed.append(rows['imageId'])\n",
    "        continue\n",
    "    h, w, c = img.shape\n",
    "    app_img = np.empty(shape=(config.MAX_PIXEL, config.MAX_PIXEL, 3), dtype=np.uint8)\n",
    "    app_img[:h, :w] = img\n",
    "    X_valid.append(app_img)\n",
    "    labels_valid.append(rows['object'])\n",
    "print(\"%d missed.\" % len(missed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 1: 0.896300601750547,\n",
       " 2: 0.9019749518304432,\n",
       " 3: 1.0751784103026822,\n",
       " 4: 1.1826671478841468}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tokenizer = text.Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels_train)\n",
    "y_train = label_tokenizer.texts_to_sequences(labels_train)\n",
    "y_valid = label_tokenizer.texts_to_sequences(labels_valid)\n",
    "y_train = np.array([_[0] for _ in y_train])\n",
    "y_valid = np.array([_[0] for _ in y_valid])\n",
    "cls_wgt = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "cls_wgt = np.array([0] + cls_wgt.tolist())\n",
    "cls_wgt = {idx: value for idx, value in enumerate(cls_wgt)}\n",
    "cls_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 2, 'outerwear': 1, 'pants': 3, 'shoe': 4}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train.astype('float32')/255.0, X_valid.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      "X_train: (52430, 32, 32, 3)\n",
      "y_train: (52430,)\n",
      "X_valid: (10473, 32, 32, 3)\n",
      "y_valid: (10473,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_valid:\", X_valid.shape)\n",
    "print(\"y_valid:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((X_train, X_valid))\n",
    "y = np.hstack((y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      "X: (62903, 32, 32, 3)\n",
      "y: (62903,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same',\n",
    "             activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer=SGD(momentum=0.5, decay=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "bst_model_path = './models/object_model.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/5...\n",
      "Train on 50321 samples, validate on 12582 samples\n",
      "Epoch 1/50\n",
      "50321/50321 [==============================] - 47s 942us/step - loss: 1.0099 - acc: 0.5794 - val_loss: 0.8626 - val_acc: 0.6512\n",
      "Epoch 2/50\n",
      "50321/50321 [==============================] - 47s 927us/step - loss: 0.7831 - acc: 0.6919 - val_loss: 0.7238 - val_acc: 0.7170\n",
      "Epoch 3/50\n",
      "50321/50321 [==============================] - 47s 932us/step - loss: 0.6843 - acc: 0.7336 - val_loss: 0.6402 - val_acc: 0.7567\n",
      "Epoch 4/50\n",
      "50321/50321 [==============================] - 47s 929us/step - loss: 0.6180 - acc: 0.7621 - val_loss: 0.6313 - val_acc: 0.7556\n",
      "Epoch 5/50\n",
      "50321/50321 [==============================] - 47s 927us/step - loss: 0.5604 - acc: 0.7858 - val_loss: 0.5791 - val_acc: 0.7807\n",
      "Epoch 6/50\n",
      "50321/50321 [==============================] - 47s 928us/step - loss: 0.5163 - acc: 0.8048 - val_loss: 0.5573 - val_acc: 0.7946\n",
      "Epoch 7/50\n",
      "50321/50321 [==============================] - 47s 932us/step - loss: 0.4726 - acc: 0.8242 - val_loss: 0.5502 - val_acc: 0.7992\n",
      "Epoch 8/50\n",
      "50321/50321 [==============================] - 47s 933us/step - loss: 0.4339 - acc: 0.8378 - val_loss: 0.5228 - val_acc: 0.8085\n",
      "Epoch 9/50\n",
      "50321/50321 [==============================] - 47s 935us/step - loss: 0.3985 - acc: 0.8531 - val_loss: 0.5135 - val_acc: 0.8174\n",
      "Epoch 10/50\n",
      "50321/50321 [==============================] - 47s 933us/step - loss: 0.3715 - acc: 0.8624 - val_loss: 0.5110 - val_acc: 0.8241\n",
      "Epoch 11/50\n",
      "50321/50321 [==============================] - 47s 932us/step - loss: 0.3378 - acc: 0.8757 - val_loss: 0.4960 - val_acc: 0.8267\n",
      "Epoch 12/50\n",
      "50321/50321 [==============================] - 47s 932us/step - loss: 0.3174 - acc: 0.8842 - val_loss: 0.4895 - val_acc: 0.8308\n",
      "Epoch 13/50\n",
      "50321/50321 [==============================] - 47s 931us/step - loss: 0.2917 - acc: 0.8948 - val_loss: 0.5006 - val_acc: 0.8321\n",
      "Epoch 14/50\n",
      "50321/50321 [==============================] - 47s 932us/step - loss: 0.2709 - acc: 0.9006 - val_loss: 0.4919 - val_acc: 0.8382\n",
      "Epoch 15/50\n",
      "50321/50321 [==============================] - 47s 934us/step - loss: 0.2493 - acc: 0.9086 - val_loss: 0.4959 - val_acc: 0.8392\n"
     ]
    }
   ],
   "source": [
    "for idx, (train_indices, valid_indices) in enumerate(skf.split(X, y)):\n",
    "    print(\"Training on fold \" + str(idx+1) + \"/\" + str(K_FOLDS) + \"...\")\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_valid, y_valid = X[valid_indices], y[valid_indices]\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_valid = to_categorical(y_valid)\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=50, \n",
    "        validation_data=(X_valid, y_valid), \n",
    "        shuffle=True, \n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        batch_size=16\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12582/12582 [==============================] - 2s 156us/step\n",
      "Accuracy: 83.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f\" % (model.evaluate(X_valid, y_valid)[-1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 2, 'outerwear': 1, 'pants': 3, 'shoe': 4}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(label_tokenizer, open('./models/object_model_label_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, c = img.shape\n",
    "    ip = np.empty(shape=(1, config.MAX_PIXEL, config.MAX_PIXEL, 3))\n",
    "    ip[0, :h, :w] = img\n",
    "    prediction = model.predict(ip)\n",
    "    return prediction[:, 1:][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class('./resized_test/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "resized_test = os.listdir(config.RESIZED_TEST_DIR)\n",
    "for _ in tqdm(resized_test, total=len(resized_test)):\n",
    "    img_path = config.RESIZED_TEST_DIR + \"/\" + _\n",
    "    all_rows.append([img_path] + predict_class(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>dress</th>\n",
       "      <th>outerwear</th>\n",
       "      <th>pants</th>\n",
       "      <th>shoe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./resized_test/2957.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./resized_test/11706.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.084036e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./resized_test/10629.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./resized_test/9810.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.784113e-04</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./resized_test/13024.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.873155e-29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img_path  dress     outerwear     pants          shoe\n",
       "0   ./resized_test/2957.jpg    0.0  1.000000e+00  0.000000  0.000000e+00\n",
       "1  ./resized_test/11706.jpg    0.0  1.000000e+00  0.000000  7.084036e-15\n",
       "2  ./resized_test/10629.jpg    0.0  0.000000e+00  0.000000  1.000000e+00\n",
       "3   ./resized_test/9810.jpg    0.0  3.784113e-04  0.999622  0.000000e+00\n",
       "4  ./resized_test/13024.jpg    1.0  3.873155e-29  0.000000  0.000000e+00"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.DataFrame(all_rows, columns = ['img_path', 'dress', 'outerwear', 'pants', 'shoe'])\n",
    "pkl.dump(df_test, open('df_test.pkl', 'wb'))\n",
    "df_test = pkl.load(open('df_test.pkl', 'rb'))\n",
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "1a4820cfa53d4500be30b541f9053611": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "30d2250218c0455899c18db9f92001ee": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "614830112cae4996bbe329d46ec57b00": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

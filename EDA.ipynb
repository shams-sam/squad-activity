{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "    \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "CSS_Flex = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "CSS_Orig = \"\"\"\n",
    ".output {\n",
    "    flex-direction: column;\n",
    "}\n",
    "\"\"\"\n",
    "def row_wise():\n",
    "    HTML('<style>{}</style>'.format(CSS_Flex))\n",
    "    \n",
    "def column_wise():\n",
    "    HTML('<style>{}</style>'.format(CSS_Orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tasks and Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_json = json.load(open(config.TASK_MAP_FILE))\n",
    "tasks = defaultdict(dict)\n",
    "task_attr_sets = defaultdict(set)\n",
    "task_label_sets = defaultdict(set)\n",
    "id_to_task_dict = {}\n",
    "for task in tasks_json['taskInfo']:\n",
    "    obj, attr = task['taskName'].split(':')\n",
    "    id_to_task_dict[task['taskId']] = task['taskName']\n",
    "    tasks[obj][attr] = task['taskId']\n",
    "    task_attr_sets[obj].add(attr)\n",
    "    task_label_sets[obj].add(task['taskId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_json = json.load(open(config.LABEL_MAP_FILE))\n",
    "label_id_to_label_map = {}\n",
    "for label in labels_json['labelInfo']:\n",
    "    label_id_to_label_map[label['labelId']] = label['labelName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = list(tasks.keys())\n",
    "attr_rows = []\n",
    "label_rows = []\n",
    "for i in objects:\n",
    "    row_attr = []\n",
    "    row_label = []\n",
    "    for j in objects:\n",
    "        row_attr.append(len(task_attr_sets[i].intersection(task_attr_sets[j])))\n",
    "        row_label.append(len(task_label_sets[i].intersection(task_label_sets[j])))\n",
    "    attr_rows.append(row_attr)\n",
    "    label_rows.append(row_label)\n",
    "df_attr_intersection = pd.DataFrame(attr_rows, index=objects, columns=objects)\n",
    "df_id_intersection = pd.DataFrame(label_rows, index=objects, columns=objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id_to_object_map = {}\n",
    "for _ in tasks_json['taskInfo']:\n",
    "    task_id_to_object_map[_['taskId']] = _['taskName'].split(\":\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id_to_attr_map = {}\n",
    "for _ in tasks_json['taskInfo']:\n",
    "    task_id_to_attr_map[_['taskId']] = _['taskName'].split(\":\")[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object And Attribute/TaskID Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Task Attribute Intersection')\n",
    "sns.heatmap(df_attr_intersection, annot=True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Task ID Intersection')\n",
    "sns.heatmap(df_id_intersection, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Train and Valid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open(config.TRAIN_DATA_FILE))\n",
    "downloaded_train_data = os.listdir(config.TRAIN_IMAGES_DIR)\n",
    "train_rows = []\n",
    "for annotation in tqdm(train_data['annotations']):\n",
    "    if annotation['imageId'] + \".jpg\" in downloaded_train_data:\n",
    "        train_rows.append([\n",
    "            annotation['imageId'], \n",
    "            annotation['labelId'], \n",
    "            annotation['taskId']\n",
    "        ])\n",
    "df_train = pd.DataFrame(train_rows, columns=['imageId', 'labelId', 'taskId'])\n",
    "valid_data = json.load(open(config.VALID_DATA_FILE))\n",
    "downloaded_valid_data = os.listdir(config.VALID_IMAGES_DIR)\n",
    "valid_rows = []\n",
    "for annotation in tqdm(valid_data['annotations']):\n",
    "    if annotation['imageId'] + \".jpg\" in downloaded_valid_data:\n",
    "        valid_rows.append([\n",
    "            annotation['imageId'], \n",
    "            annotation['labelId'], \n",
    "            annotation['taskId']\n",
    "        ])\n",
    "df_valid = pd.DataFrame(valid_rows, columns=['imageId', 'labelId', 'taskId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, rows in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    df_train.at[idx, 'object'] = task_id_to_object_map[rows['taskId']]\n",
    "    df_train.at[idx, 'attribute'] = task_id_to_attr_map[rows['taskId']]\n",
    "    df_train.at[idx, 'label'] = label_id_to_label_map[rows['labelId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, rows in tqdm(df_valid.iterrows(), total=len(df_valid)):\n",
    "    df_valid.at[idx, 'object'] = task_id_to_object_map[rows['taskId']]\n",
    "    df_valid.at[idx, 'attribute'] = task_id_to_attr_map[rows['taskId']]\n",
    "    df_valid.at[idx, 'label'] = label_id_to_label_map[rows['labelId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pkl\n",
    "pkl.dump(df_train, open('./data/df_train.dump.pkl', 'wb'))\n",
    "pkl.dump(df_valid, open('./data/df_valid.dump.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "df_train.taskId.value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Task Distribution in Training Data')\n",
    "plt.xlabel('taskId')\n",
    "plt.ylabel('#instances')\n",
    "plt.subplot(1, 2, 2)\n",
    "df_valid.taskId.value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Task Distribution in Validation Data')\n",
    "plt.xlabel('taskId')\n",
    "plt.ylabel('#instances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Label Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids = df_train.taskId.unique().tolist()\n",
    "task_label_rows = []\n",
    "for i in task_ids:\n",
    "    row = []\n",
    "    for j in task_ids:\n",
    "        intersection = set(\n",
    "            df_train[df_train.taskId == i].labelId.unique()\n",
    "        ).intersection(\n",
    "            df_train[df_train.taskId == j].labelId.unique()\n",
    "        )\n",
    "        row.append(len(intersection))\n",
    "    task_label_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [id_to_task_dict[_] for _ in task_ids]\n",
    "df_task_label_intersection = pd.DataFrame(task_label_rows, index=tasks, columns=tasks)\n",
    "plt.figure(figsize=(11, 10))\n",
    "plt.title('Task Label Intersection')\n",
    "sns.heatmap(df_task_label_intersection, annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for task in df_train.taskId.sort_values().unique().tolist():\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df_train[df_train.taskId == task].labelId.value_counts().sort_index().plot(kind='bar')\n",
    "    plt.title('Label Distribution in Training Data for Task: ' + str(task) + ' (' + id_to_task_dict[task] + ')')\n",
    "    plt.xlabel('labelId')\n",
    "    plt.ylabel('#instances')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    df_valid[df_valid.taskId == task].labelId.value_counts().sort_index().plot(kind='bar')\n",
    "    plt.title('Label Distribution in Validation Data for Task: ' + str(task) + ' (' + id_to_task_dict[task] + ')')\n",
    "    plt.xlabel('labelId')\n",
    "    plt.ylabel('#instances')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Dimension Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = []\n",
    "height = []\n",
    "channels = []\n",
    "for _ in tqdm(df_train.imageId.unique().tolist()):\n",
    "    img = cgv2.imread(_)\n",
    "    try:\n",
    "        x, y, z = img.shape\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    width.append(y)\n",
    "    height.append(x)\n",
    "    channels.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_new = []\n",
    "height_new = []\n",
    "channels_new = []\n",
    "for _ in tqdm(df_train.imageId.unique().tolist()):\n",
    "    _ = _.replace(config.TRAIN_IMAGES_DIR, config.RESIZED_TRAIN_DIR)\n",
    "    img = cv2.imread(_)\n",
    "    try:\n",
    "        x, y, z = img.shape\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    width_new.append(y)\n",
    "    height_new.append(x)\n",
    "    channels_new.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Height Distribution\")\n",
    "plt.ylabel('Heights')\n",
    "plt.xlabel('Instance #')\n",
    "plt.plot(list(range(len(height))), height, 'b', list(range(len(height_new))), height_new, 'r')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Width Distribution\")\n",
    "plt.ylabel('Width')\n",
    "plt.xlabel('Instance #')\n",
    "plt.plot(list(range(len(width))), width, 'b', list(range(len(width_new))), width_new, 'r')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Channel Distribution\")\n",
    "plt.ylabel('Channels')\n",
    "plt.xlabel('Instance #')\n",
    "plt.plot(list(range(len(channels))), channels, 'b', list(range(len(channels_new))), channels_new, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Dimension Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_stats = pd.DataFrame.from_dict({'height': height, 'width': width, 'channel': channels})\n",
    "df_resized_stats = pd.DataFrame.from_dict({'height': height_new, 'width': width_new, 'channel': channels_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['height', 'width', 'channel']\n",
    "for df_name, df in {'Original': df_image_stats, 'Resized': df_resized_stats}.items():\n",
    "    print(df_name)\n",
    "    for _ in cols:\n",
    "        print(\"\\t\" + _)\n",
    "        print(\"\\t\\tMax\", df[_].max())\n",
    "        print(\"\\t\\tMin\", df[_].min())\n",
    "        print(\"\\t\\tMean\", df[_].mean())\n",
    "        print(\"\\t\\tMedian\", df[_].median())\n",
    "        print(\"\\t\\tMode\", df[_].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are a total of 4 objects - **['dress', 'outerwear', 'pants', 'shoe']** over which the attributes are to be predicted.\n",
    "- **Attributes intersect** between two given objects but the **task IDs assigned to these attributes are exclusive**. Because of this it would be possible to train a classifier at object level.\n",
    "- Labels are practically exclusive (with **limited intersections**) since the values on-diagonal are much greater than those off-diagonal\n",
    "- The **validation split is stratified** as the distributions of **task IDs over the training and testing images**, and **labels over task IDs** is similar.\n",
    "- Image dimensions suggest that **reshaping** would be required as the input to pretrained models in keras is around **299*299** and training a bigger image set would also required higher system configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the attributes are related to objects, **use pretrained Image-VGG model weights** to re-train the 4 class object classifier.\n",
    "- Better to use **Xception Model** with the current system configuration and time constraints.\n",
    "- Based on the reported accuracies **InceptionResNetV2** would be the ideal choice.\n",
    "- As a next step there has to be **individual classifier for most of the tasks**.\n",
    "- Keep as **N/A class for each classifier to assign negative samples**.\n",
    "- Consider the final probability as the **conditional probability** of an attribute given the probability of an object\n",
    "- **Note**: The image URLs can be used as the **leaky feature** for the attribute classification task"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  },
  "widgets": {
   "state": {
    "3fa3bf55358b41bca664604385ffadc0": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4c91e8b62d1e48e594a8459bdf4d9d89": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "54f2117273764926991420a82e5a6e25": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "57ca8910d3804450b53f3fee5f0d1ab8": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "77884887bdf245b48017f2886d144dc1": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "85981fe3949849948c02d0350133e3db": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
